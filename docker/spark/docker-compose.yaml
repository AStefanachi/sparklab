version: '3'

services:
  spark-master:
    env_file: spark.env # Uses .env variables

    build:
      context: .
      dockerfile: Dockerfile      

    ports:
      - "7077:7077"  # Spark master port
      - "8080:8080"  # Spark master web UI port
      - "4040:4040"  # Spark App gui
      - "8888:8888"  # Jupyter Lab 

    environment:
      - SPARK_MASTER_HOST=${SPARK_MASTER_HOST}
      - SPARK_MASTER_PORT=${SPARK_MASTER_PORT}
      - SPARK_LOCAL_HOSTNAME=${SPARK_LOCAL_HOSTNAME}
      - SPARK_HOME=${SPARK_HOME}

    command: bash -c "$$SPARK_HOME/sbin/start-master.sh && jupyter lab --ip=0.0.0.0 --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.notebook_dir='$SPARK_HOME/data-mount' --allow-root"

    volumes:
      - ../../master-data:${SPARK_HOME}/data-mount

    networks:
      - spark-network

  spark-worker:
    env_file: spark.env # Uses .env variables  
    build:
      context: .
      dockerfile: Dockerfile

    ports:
      - "8081:8081" # Spark Worker web UI

    environment:
      - SPARK_MASTER_HOST=${SPARK_MASTER_HOST}
      - SPARK_MASTER_PORT=${SPARK_MASTER_PORT}
      - SPARK_LOCAL_HOSTNAME=${SPARK_LOCAL_HOSTNAME}
      - SPARK_HOME=${SPARK_HOME}    
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}  # Number of cores for the Spark worker
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}  # Memory for the Spark worker 

 
    command: bash -c "$$SPARK_HOME/sbin/start-worker.sh spark://spark-master:7077 && sleep infinity"

    volumes:
      - ../../worker-data:${SPARK_HOME}/data-mount
      
    networks:
      - spark-network

networks:
  spark-network:
    external: true
    driver: bridge
